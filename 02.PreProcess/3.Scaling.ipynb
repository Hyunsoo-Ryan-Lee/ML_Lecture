{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "![](https://velog.velcdn.com/images/newnew_daddy/post/ab0abca9-2dcd-4e8d-b790-d971e1b5b0c2/image.png)\n",
    "- 스케일링되지 않은 데이터는 특정 특성이 다른 특성보다 더 큰 영향을 미칠 수 있음\n",
    "- 데이터의 각 특징이 동일한 범위에 있도록 조정하여 모델 학습을 최적화하는 데 사용\n",
    "- 스케일링을 통해 알고리즘의 수렴 속도를 높이고, 특성이 서로 다른 단위로 인해 발생할 수 있는 문제점을 줄임.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(20, 4) * 100\n",
    "df = pd.DataFrame(data, columns=['feature1', 'feature2', 'feature3', 'feature4'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규분포 시각화 (하나의 그래프에 선형 그래프만)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for col in df.columns:\n",
    "    sns.kdeplot(df[col], label=col)\n",
    "\n",
    "plt.title('Distributions of Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Standard Scaler\n",
    "- 평균이 0이고 분산이 1이 되도록 데이터의 각 특징을 스케일링합니다.\n",
    "- 데이터가 정규분포를 따를 때 유용하며, SVM이나 로지스틱 회귀와 같은 모델에 적합합니다.\n",
    "- [1, 2, 3, 4, 5] -> [-1.26, -0.63, 0, 0.63, 1.26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = scaler_standard.fit_transform(df)\n",
    "\n",
    "df_standard = pd.DataFrame(df_standard, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MinMax Scaler\n",
    "- 데이터의 각 특징을 최소값 0, 최대값 1로 변환합니다.\n",
    "- 값의 범위가 고정되어 있어, 신경망이나 k-NN 모델에서 많이 사용됩니다.\n",
    "- [1, 2, 3, 4, 5] -> [0, 0.25, 0.5, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = scaler_minmax.fit_transform(df)\n",
    "\n",
    "df_minmax = pd.DataFrame(df_minmax, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Robust Scaler\n",
    "- 중앙값(median)과 IQR(Interquartile Range)을 사용하여 스케일링하여 극단값(outliers)의 영향을 줄입니다.\n",
    "- 데이터에 이상치가 많을 때 사용하면 효과적입니다.\n",
    "- [1, 2, 3, 4, 5] -> [-1, -0.5, 0, 0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_robust = RobustScaler()\n",
    "df_robust = scaler_robust.fit_transform(df)\n",
    "\n",
    "df_robust = pd.DataFrame(df_robust, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Normalizer\n",
    "- 각 데이터 포인트의 크기를 1로 만들기 위해 개별 벡터를 정규화합니다.\n",
    "- 주로 문서 벡터나 피처 간의 유사성을 비교할 때 사용됩니다.\n",
    "- [[1, 2], [2, 3]] -> [[0.45, 0.89], [0.55, 0.83]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler_normalizer = Normalizer()\n",
    "df_normalizer = scaler_normalizer.fit_transform(df)\n",
    "\n",
    "df_normalizer = pd.DataFrame(df_normalizer, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 정규화 비교 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규분포 시각화 (하나의 그래프에 선형 그래프만)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for col in df_standard.columns:\n",
    "    sns.kdeplot(df_standard[col], label=col)\n",
    "\n",
    "plt.title('Distributions of Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plt.subplot(nrows, ncols, index)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "plt.subplot(1, 5, 1)\n",
    "for col in df.columns:\n",
    "    sns.kdeplot(df[col], label=col)\n",
    "\n",
    "plt.subplot(1, 5, 2)\n",
    "for col in df_standard.columns:\n",
    "    sns.kdeplot(df_standard[col], label=col)\n",
    "\n",
    "plt.subplot(1, 5, 3)\n",
    "for col in df_minmax.columns:\n",
    "    sns.kdeplot(df_minmax[col], label=col)\n",
    "\n",
    "plt.subplot(1, 5, 4)\n",
    "for col in df_robust.columns:\n",
    "    sns.kdeplot(df_robust[col], label=col)\n",
    "\n",
    "plt.subplot(1, 5, 5)\n",
    "for col in df_normalizer.columns:\n",
    "    sns.kdeplot(df_normalizer[col], label=col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
